{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012172,
     "end_time": "2021-02-24T17:40:46.004492",
     "exception": false,
     "start_time": "2021-02-24T17:40:45.992320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Kaggle Competition : Jane Street Market Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010343,
     "end_time": "2021-02-24T17:40:46.025303",
     "exception": false,
     "start_time": "2021-02-24T17:40:46.014960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " $\\rule{20cm}{0.1pt}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010242,
     "end_time": "2021-02-24T17:40:46.045748",
     "exception": false,
     "start_time": "2021-02-24T17:40:46.035506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook details\n",
    "\n",
    "cf. https://www.kaggle.com/lunatik62/pytorch-tagmodels-stacking-1-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010562,
     "end_time": "2021-02-24T17:40:46.066640",
     "exception": false,
     "start_time": "2021-02-24T17:40:46.056078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Load Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T17:40:46.095047Z",
     "iopub.status.busy": "2021-02-24T17:40:46.094292Z",
     "iopub.status.idle": "2021-02-24T17:40:48.789286Z",
     "shell.execute_reply": "2021-02-24T17:40:48.788446Z"
    },
    "papermill": {
     "duration": 2.712173,
     "end_time": "2021-02-24T17:40:48.789545",
     "exception": false,
     "start_time": "2021-02-24T17:40:46.077372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version : 1.7.0\n",
      "GPU : Tesla P100-PCIE-16GB available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datatable as dt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from scipy.special import expit\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f\"Pytorch version : {torch.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU : {torch.cuda.get_device_name()} available\")\n",
    "else:\n",
    "    print(\"Error : GPU not available\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011098,
     "end_time": "2021-02-24T17:40:48.814269",
     "exception": false,
     "start_time": "2021-02-24T17:40:48.803171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T17:40:48.849994Z",
     "iopub.status.busy": "2021-02-24T17:40:48.849010Z",
     "iopub.status.idle": "2021-02-24T17:40:48.852213Z",
     "shell.execute_reply": "2021-02-24T17:40:48.851771Z"
    },
    "papermill": {
     "duration": 0.026624,
     "end_time": "2021-02-24T17:40:48.852333",
     "exception": false,
     "start_time": "2021-02-24T17:40:48.825709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    return None\n",
    "\n",
    "def utility(dates, weights, true_resp, actions, use_mult=False):\n",
    "    \"\"\"Jane Street evaluation metric\"\"\"\n",
    "    Pi = weights * true_resp * actions\n",
    "    if use_mult:\n",
    "        mult = np.sqrt(250 / np.bincount(dates).shape[0])\n",
    "    else:\n",
    "        mult = 1\n",
    "    sum_Pi = Pi.sum() \n",
    "    sum_pi_squared = np.sqrt((Pi ** 2).sum())\n",
    "    t = (sum_Pi / sum_pi_squared) * mult\n",
    "    u = min(max(t, 0), 6) * sum_Pi\n",
    "    return u\n",
    "\n",
    "def compute_utility_many(predictions, dates, weights, true_resp, interval=np.linspace(0, 1, 101)):\n",
    "    \"\"\"given predictions probability compute utility for many threshold\"\"\"\n",
    "    lst_ut = []\n",
    "    for v in interval:\n",
    "        actions =  (predictions > v).astype(int)\n",
    "        ut = utility(dates=dates, weights=weights, true_resp=true_resp, actions=actions)\n",
    "        lst_ut.append((v, ut))\n",
    "    return lst_ut\n",
    "\n",
    "def build_dic_records(datasets=[], records=[]):\n",
    "    \"\"\"save training data into python dict\"\"\"\n",
    "    dic = {}\n",
    "    for dataset in datasets:\n",
    "        dic[dataset] = {}\n",
    "        for record in records:\n",
    "            dic[dataset][record] = []\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011866,
     "end_time": "2021-02-24T17:40:48.875837",
     "exception": false,
     "start_time": "2021-02-24T17:40:48.863971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T17:40:48.911239Z",
     "iopub.status.busy": "2021-02-24T17:40:48.909232Z",
     "iopub.status.idle": "2021-02-24T17:40:48.911829Z",
     "shell.execute_reply": "2021-02-24T17:40:48.912255Z"
    },
    "papermill": {
     "duration": 0.024215,
     "end_time": "2021-02-24T17:40:48.912414",
     "exception": false,
     "start_time": "2021-02-24T17:40:48.888199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "DATE_NOW = datetime.now().__format__(\"%Y-%m-%d_%H:%M:%S\")\n",
    "DATE_TRAINING_TAGMODEL = \"2021-02-16_154406\"\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "PATH_ROOT = \"/kaggle/input/jane-street-market-prediction\"\n",
    "PATH_WEIGHT_TAGMODEL = \"../input/weights-tagmodels/\"\n",
    "PATH_WEIGHT_STACKMODEL = \"../input/weightsstackedmodel/StackedModel_2021-02-17_135144.pt\"\n",
    "\n",
    "PATH_DATA = os.path.join(PATH_ROOT, \"train.csv\")\n",
    "PATH_FEATURES =  os.path.join(PATH_ROOT, \"features.csv\")\n",
    "\n",
    "LST_FEATURES = [\"feature_\"+str(n_feat) for n_feat in range(0, 130, 1)]\n",
    "LST_TARGETS = [\"resp\", \"resp_1\", \"resp_2\", \"resp_3\", \"resp_4\"]\n",
    "\n",
    "TRAIN_PREVIOUS_LAYERS = False\n",
    "THRESHOLD = .5\n",
    "SIZE_TRAIN = .85\n",
    "TRAINING = False\n",
    "SAVE_DICT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011515,
     "end_time": "2021-02-24T17:40:48.935664",
     "exception": false,
     "start_time": "2021-02-24T17:40:48.924149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T17:40:48.968423Z",
     "iopub.status.busy": "2021-02-24T17:40:48.967610Z",
     "iopub.status.idle": "2021-02-24T17:41:56.609849Z",
     "shell.execute_reply": "2021-02-24T17:41:56.610253Z"
    },
    "papermill": {
     "duration": 67.661894,
     "end_time": "2021-02-24T17:41:56.610436",
     "exception": false,
     "start_time": "2021-02-24T17:40:48.948542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (1862597, 138)\n",
      "CPU times: user 28.4 s, sys: 9.79 s, total: 38.2 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(seed=SEED)\n",
    "\n",
    "data = dt.fread(PATH_DATA).to_pandas()  # fast loading\n",
    "data = data[data.date > 85]  # delete date < 85\n",
    "data = data.sample(frac=1)  # shuffle\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(f\"shape : {data.shape}\")\n",
    "\n",
    "df_tags = pd.read_csv(PATH_FEATURES, index_col=\"feature\")\n",
    "dic_tags = {}\n",
    "for n, tag in enumerate(df_tags.columns):\n",
    "    lst_features = df_tags[tag][df_tags[tag] == True].index.tolist()\n",
    "    lst_num_features = [int(e.strip(\"feature_\")) for e in lst_features]\n",
    "    dic_tags[str(n)] = lst_num_features\n",
    "\n",
    "# add feature_0 in all tags\n",
    "for e in dic_tags.keys():\n",
    "    dic_tags[e].append(0)\n",
    "    \n",
    "f_mean = data[LST_FEATURES[1:]].mean()\n",
    "f_mean[\"feature_0\"] = 1\n",
    "f_mean.sort_index()\n",
    "data = data.loc[data.weight > 0].reset_index(drop = True)  # delete 0 weight data\n",
    "data[LST_FEATURES[1:]] = data[LST_FEATURES[1:]].fillna(f_mean)  # filling NaN by mean of each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011591,
     "end_time": "2021-02-24T17:41:56.634495",
     "exception": false,
     "start_time": "2021-02-24T17:41:56.622904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Pytorch utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T17:41:56.693008Z",
     "iopub.status.busy": "2021-02-24T17:41:56.672081Z",
     "iopub.status.idle": "2021-02-24T17:41:56.731856Z",
     "shell.execute_reply": "2021-02-24T17:41:56.731360Z"
    },
    "papermill": {
     "duration": 0.085603,
     "end_time": "2021-02-24T17:41:56.731962",
     "exception": false,
     "start_time": "2021-02-24T17:41:56.646359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \n",
    "    def __init__(self, patience=7, mode=\"max\", delta=0.0, verbose=False, trace_func=print, path=\"checkpoint.pt\"):\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.trace_func = trace_func\n",
    "        self.path = path\n",
    "        \n",
    "        if self.mode == \"min\":\n",
    "            self.val_score = np.Inf\n",
    "            \n",
    "        else:\n",
    "            self.val_score = -np.Inf\n",
    "\n",
    "    def __call__(self, epoch_score, model):\n",
    "\n",
    "        if self.mode == \"min\":\n",
    "            score = -1.0 * epoch_score\n",
    "            \n",
    "        elif self.mode == \"max\":\n",
    "            score = np.copy(epoch_score)\n",
    "        \n",
    "        # first epoch\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model)\n",
    "        \n",
    "        # best score NOT modified\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                \n",
    "        # best score modified        \n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, epoch_score, model):\n",
    "        \"\"\"\n",
    "        Save model when validation loss decrease.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation metric moving : ({self.val_score:.6f} --> {epoch_score:.6f}).  Saving model ...')\n",
    "            \n",
    "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            \n",
    "        self.val_score = epoch_score\n",
    "\n",
    "class BuildDataset:\n",
    "    \n",
    "    def __init__(self, df, col_x, target):\n",
    "        self.col_x = col_x.copy()\n",
    "        self.target = target.copy()\n",
    "        self.X = df[self.col_x].values\n",
    "        self.y = (df[self.target] > 0).astype('int').values\n",
    "        self.weights = df.weight.values\n",
    "        self.resps = df.resp.values\n",
    "        self.actions = (df.resp > 0 ).astype('int').values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.X[idx], dtype=torch.float),\n",
    "            'label': torch.tensor(self.y[idx], dtype=torch.float),\n",
    "            'weights': torch.tensor(self.weights[idx], dtype=torch.float),\n",
    "            'resps': torch.tensor(self.resps[idx], dtype=torch.float),\n",
    "            'actions': torch.tensor(self.actions[idx], dtype=torch.float)\n",
    "        }\n",
    "    \n",
    "class P1UtilityLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    customized loss based on first part of utility evaluation metric\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, threshold=.5):\n",
    "        super(P1UtilityLoss, self).__init__()\n",
    "        self.threshold = torch.tensor(threshold)\n",
    "        \n",
    "    def forward(self, true_actions, pred, weights, resps):\n",
    "        w_r = torch.mul(weights, resps)\n",
    "        pi_true = torch.mul(w_r, true_actions)\n",
    "        pi_pred = torch.mul(w_r, pred)\n",
    "        pi_true_sum = torch.sum(pi_true)\n",
    "        pi_pred_sum = torch.sum(pi_pred)\n",
    "        res = torch.sub(torch.tensor(1), torch.div(pi_pred_sum, pi_true_sum))\n",
    "        return res\n",
    "\n",
    "class TagModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    MLP : batchnorm0 > dropout > dense0 > relu > batchnorm1 > dropout > dense1 > sigmoid\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dic_tags, tag_number, input_size, output_size, threshold=.5, rate_dropout=.1):\n",
    "        \n",
    "        super(TagModel, self).__init__()\n",
    "        self.dic_tags = dic_tags\n",
    "        self.tag_number = str(tag_number)\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.rate_dropout = rate_dropout\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(self.rate_dropout)\n",
    "        self.batch_norm0 = nn.BatchNorm1d(len(self.dic_tags[self.tag_number]))\n",
    "        self.batch_norm1 = nn.BatchNorm1d(2 * len(self.dic_tags[self.tag_number]))\n",
    "        self.dense0 = torch.nn.Linear(\n",
    "            len(self.dic_tags[self.tag_number]),\n",
    "            2 * len(self.dic_tags[self.tag_number])\n",
    "        )\n",
    "        self.dense1 = torch.nn.Linear(\n",
    "            2 * len(self.dic_tags[self.tag_number]),\n",
    "            self.output_size\n",
    "        )\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.batch_norm0(x[:, self.dic_tags[self.tag_number]])\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense0(x)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "class StackedModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, dic_tags, path_weights, date_training_tag, rate_dropout=.1, train_previous_layers=False, device=DEVICE):\n",
    "        super(StackedModel, self).__init__()\n",
    "\n",
    "        self.dic_tags = dic_tags\n",
    "        self.path_weights = path_weights\n",
    "        self.rate_dropout = rate_dropout\n",
    "        self.date_training_tag = date_training_tag\n",
    "        self.train_previous_layers = train_previous_layers\n",
    "        self.device = DEVICE\n",
    "        \n",
    "        # load 29 TagModels\n",
    "        self.model0 = TagModel(dic_tags=self.dic_tags, tag_number=0, input_size=130, output_size=1).to(self.device)\n",
    "        self.model1 = TagModel(dic_tags=self.dic_tags, tag_number=1, input_size=130, output_size=1).to(self.device)\n",
    "        self.model2 = TagModel(dic_tags=self.dic_tags, tag_number=2, input_size=130, output_size=1).to(self.device)\n",
    "        self.model3 = TagModel(dic_tags=self.dic_tags, tag_number=3, input_size=130, output_size=1).to(self.device)\n",
    "        self.model4 = TagModel(dic_tags=self.dic_tags, tag_number=4, input_size=130, output_size=1).to(self.device)\n",
    "        self.model5 = TagModel(dic_tags=self.dic_tags, tag_number=5, input_size=130, output_size=1).to(self.device)\n",
    "        self.model6 = TagModel(dic_tags=self.dic_tags, tag_number=6, input_size=130, output_size=1).to(self.device)\n",
    "        self.model7 = TagModel(dic_tags=self.dic_tags, tag_number=7, input_size=130, output_size=1).to(self.device)\n",
    "        self.model8 = TagModel(dic_tags=self.dic_tags, tag_number=8, input_size=130, output_size=1).to(self.device)\n",
    "        self.model9 = TagModel(dic_tags=self.dic_tags, tag_number=9, input_size=130, output_size=1).to(self.device)\n",
    "        self.model10 = TagModel(dic_tags=self.dic_tags, tag_number=10, input_size=130, output_size=1).to(self.device)\n",
    "        self.model11 = TagModel(dic_tags=self.dic_tags, tag_number=11, input_size=130, output_size=1).to(self.device)\n",
    "        self.model12 = TagModel(dic_tags=self.dic_tags, tag_number=12, input_size=130, output_size=1).to(self.device)\n",
    "        self.model13 = TagModel(dic_tags=self.dic_tags, tag_number=13, input_size=130, output_size=1).to(self.device)\n",
    "        self.model14 = TagModel(dic_tags=self.dic_tags, tag_number=14, input_size=130, output_size=1).to(self.device)\n",
    "        self.model15 = TagModel(dic_tags=self.dic_tags, tag_number=15, input_size=130, output_size=1).to(self.device)\n",
    "        self.model16 = TagModel(dic_tags=self.dic_tags, tag_number=16, input_size=130, output_size=1).to(self.device)\n",
    "        self.model17 = TagModel(dic_tags=self.dic_tags, tag_number=17, input_size=130, output_size=1).to(self.device)\n",
    "        self.model18 = TagModel(dic_tags=self.dic_tags, tag_number=18, input_size=130, output_size=1).to(self.device)\n",
    "        self.model19 = TagModel(dic_tags=self.dic_tags, tag_number=19, input_size=130, output_size=1).to(self.device)\n",
    "        self.model20 = TagModel(dic_tags=self.dic_tags, tag_number=20, input_size=130, output_size=1).to(self.device)\n",
    "        self.model21 = TagModel(dic_tags=self.dic_tags, tag_number=21, input_size=130, output_size=1).to(self.device)\n",
    "        self.model22 = TagModel(dic_tags=self.dic_tags, tag_number=22, input_size=130, output_size=1).to(self.device)\n",
    "        self.model23 = TagModel(dic_tags=self.dic_tags, tag_number=23, input_size=130, output_size=1).to(self.device)\n",
    "        self.model24 = TagModel(dic_tags=self.dic_tags, tag_number=24, input_size=130, output_size=1).to(self.device)\n",
    "        self.model25 = TagModel(dic_tags=self.dic_tags, tag_number=25, input_size=130, output_size=1).to(self.device)\n",
    "        self.model26 = TagModel(dic_tags=self.dic_tags, tag_number=26, input_size=130, output_size=1).to(self.device)\n",
    "        self.model27 = TagModel(dic_tags=self.dic_tags, tag_number=27, input_size=130, output_size=1).to(self.device)\n",
    "        self.model28 = TagModel(dic_tags=self.dic_tags, tag_number=28, input_size=130, output_size=1).to(self.device)\n",
    "        \n",
    "        # load their weights\n",
    "        self.model0.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel0_{self.date_training_tag}.pt\")))\n",
    "        self.model1.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel1_{self.date_training_tag}.pt\")))\n",
    "        self.model2.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel2_{self.date_training_tag}.pt\")))\n",
    "        self.model3.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel3_{self.date_training_tag}.pt\")))\n",
    "        self.model4.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel4_{self.date_training_tag}.pt\")))\n",
    "        self.model5.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel5_{self.date_training_tag}.pt\")))\n",
    "        self.model6.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel6_{self.date_training_tag}.pt\")))\n",
    "        self.model7.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel7_{self.date_training_tag}.pt\")))\n",
    "        self.model8.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel8_{self.date_training_tag}.pt\")))\n",
    "        self.model9.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel9_{self.date_training_tag}.pt\")))\n",
    "        self.model10.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel10_{self.date_training_tag}.pt\")))\n",
    "        self.model11.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel11_{self.date_training_tag}.pt\")))\n",
    "        self.model12.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel12_{self.date_training_tag}.pt\")))\n",
    "        self.model13.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel13_{self.date_training_tag}.pt\")))\n",
    "        self.model14.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel14_{self.date_training_tag}.pt\")))\n",
    "        self.model15.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel15_{self.date_training_tag}.pt\")))\n",
    "        self.model16.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel16_{self.date_training_tag}.pt\")))\n",
    "        self.model17.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel17_{self.date_training_tag}.pt\")))\n",
    "        self.model18.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel18_{self.date_training_tag}.pt\")))\n",
    "        self.model19.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel19_{self.date_training_tag}.pt\")))\n",
    "        self.model20.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel20_{self.date_training_tag}.pt\")))\n",
    "        self.model21.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel21_{self.date_training_tag}.pt\")))\n",
    "        self.model22.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel22_{self.date_training_tag}.pt\")))\n",
    "        self.model23.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel23_{self.date_training_tag}.pt\")))\n",
    "        self.model24.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel24_{self.date_training_tag}.pt\")))\n",
    "        self.model25.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel25_{self.date_training_tag}.pt\")))\n",
    "        self.model26.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel26_{self.date_training_tag}.pt\")))\n",
    "        self.model27.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel27_{self.date_training_tag}.pt\")))\n",
    "        self.model28.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel28_{self.date_training_tag}.pt\")))\n",
    "        \n",
    "        # fix weights of TagModels only\n",
    "        if not self.train_previous_layers:\n",
    "            self.model0.eval()\n",
    "            self.model1.eval()\n",
    "            self.model2.eval()\n",
    "            self.model3.eval()\n",
    "            self.model4.eval()\n",
    "            self.model5.eval()\n",
    "            self.model6.eval()\n",
    "            self.model7.eval()\n",
    "            self.model8.eval()\n",
    "            self.model9.eval()\n",
    "            self.model10.eval()\n",
    "            self.model11.eval()\n",
    "            self.model12.eval()\n",
    "            self.model13.eval()\n",
    "            self.model14.eval()\n",
    "            self.model15.eval()\n",
    "            self.model16.eval()\n",
    "            self.model17.eval()\n",
    "            self.model18.eval()\n",
    "            self.model19.eval()\n",
    "            self.model20.eval()\n",
    "            self.model21.eval()\n",
    "            self.model22.eval()\n",
    "            self.model23.eval()\n",
    "            self.model24.eval()\n",
    "            self.model25.eval()\n",
    "            self.model26.eval()\n",
    "            self.model27.eval()\n",
    "            self.model28.eval()\n",
    "                \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(self.rate_dropout)\n",
    "        self.batch_norm0 = nn.BatchNorm1d(60)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(5)\n",
    "        \n",
    "        self.dense0 = torch.nn.Linear(30, 60)\n",
    "        self.dense1 = torch.nn.Linear(60, 5)\n",
    "        self.dense2 = torch.nn.Linear(5, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feature_0 = torch.reshape(x[:, 0], (-1, 1))\n",
    "        \n",
    "        # xi is output of TagModeli\n",
    "        x0 = self.model0(x)\n",
    "        x1 = self.model1(x)\n",
    "        x2 = self.model2(x)\n",
    "        x3 = self.model3(x)\n",
    "        x4 = self.model4(x)\n",
    "        x5 = self.model5(x)\n",
    "        x6 = self.model6(x)\n",
    "        x7 = self.model7(x)\n",
    "        x8 = self.model8(x)\n",
    "        x9 = self.model9(x)\n",
    "        x10 = self.model10(x)\n",
    "        x11 = self.model11(x)\n",
    "        x12 = self.model12(x)\n",
    "        x13 = self.model13(x)\n",
    "        x14 = self.model14(x)\n",
    "        x15 = self.model15(x)\n",
    "        x16 = self.model16(x)\n",
    "        x17 = self.model17(x)\n",
    "        x18 = self.model18(x)\n",
    "        x19 = self.model19(x)\n",
    "        x20 = self.model20(x)\n",
    "        x21 = self.model21(x)\n",
    "        x22 = self.model22(x)\n",
    "        x23 = self.model23(x)\n",
    "        x24 = self.model24(x)\n",
    "        x25 = self.model25(x)\n",
    "        x26 = self.model26(x)\n",
    "        x27 = self.model27(x)\n",
    "        x28 = self.model28(x)\n",
    "        \n",
    "        x = torch.cat(\n",
    "            (\n",
    "                feature_0,\n",
    "                x0, x1, x2, x3, x4, x5, x6, x7, x8, x9,\n",
    "                x10, x11, x12, x13, x14, x15, x16, x17, x18, x19,\n",
    "                x20, x21, x22, x23, x24, x25, x26, x27, x28\n",
    "            ), 1\n",
    "        )\n",
    "        \n",
    "        x = self.dense0(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.batch_norm0(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011637,
     "end_time": "2021-02-24T17:41:56.755425",
     "exception": false,
     "start_time": "2021-02-24T17:41:56.743788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Training all TagModel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T17:41:56.809635Z",
     "iopub.status.busy": "2021-02-24T17:41:56.787196Z",
     "iopub.status.idle": "2021-02-24T17:41:56.811878Z",
     "shell.execute_reply": "2021-02-24T17:41:56.812314Z"
    },
    "papermill": {
     "duration": 0.045101,
     "end_time": "2021-02-24T17:41:56.812440",
     "exception": false,
     "start_time": "2021-02-24T17:41:56.767339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model : architecture\n",
    "batch_size = 16384\n",
    "input_size = 130\n",
    "output_size = 1\n",
    "\n",
    "# Model : training\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "threshold =.5\n",
    "es_mode = \"min\"\n",
    "patience = 3\n",
    "\n",
    "dic_records = build_dic_records(\n",
    "            datasets=[\"train\", \"val\"],\n",
    "            records=[\"lst_loss_epoch\", \"lst_loss_batch\", \"lst_utility\", \"lst_accuracy\", \"lst_precision\", \"lst_recall\"]\n",
    ")\n",
    "\n",
    "if TRAINING:\n",
    "\n",
    "    # sample data\n",
    "    data = data.sample(frac=1)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    train_index = [e for e in range(0, int(data.shape[0] * SIZE_TRAIN), 1)]\n",
    "    val_index = [e for e in range(max(train_index), data.shape[0], 1)]\n",
    "\n",
    "    # build sets for training\n",
    "    train = data.loc[train_index]\n",
    "    val = data.loc[val_index]\n",
    "    train_set = BuildDataset(df=train.loc[train_index], col_x=LST_FEATURES, target=LST_TARGETS)\n",
    "    val_set = BuildDataset(df=val.loc[val_index], col_x=LST_FEATURES, target=LST_TARGETS)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size)\n",
    "\n",
    "    # compute and save perfect utility for each set\n",
    "    perfect_train_utility = utility(dates=train.date.values, weights=train.weight.values, true_resp=train.resp.values, actions=(train.resp > 0).astype(int))\n",
    "    perfect_val_utility = utility(dates=val.date.values, weights=val.weight.values, true_resp=val.resp.values, actions=(val.resp > 0).astype(int))\n",
    "    dic_records[\"train\"][\"perfect_utility\"] = perfect_train_utility\n",
    "    dic_records[\"val\"][\"perfect_utility\"] = perfect_val_utility\n",
    "    dic_records[\"train\"][\"lst_index\"] = train_index\n",
    "    dic_records[\"val\"][\"lst_index\"] = val_index\n",
    "\n",
    "    # define utils for model\n",
    "    torch.cuda.empty_cache()\n",
    "    model = StackedModel(\n",
    "        dic_tags=dic_tags, path_weights=PATH_WEIGHT_TAGMODEL, date_training_tag=DATE_TRAINING_TAGMODEL,train_previous_layers=TRAIN_PREVIOUS_LAYERS, device=DEVICE\n",
    "    ).to(DEVICE)\n",
    "    p1_utility_loss = P1UtilityLoss(threshold)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    path_model = f\"./StackedModel_{DATE_NOW}.pt\"\n",
    "    early_stopping = EarlyStopping(mode=es_mode, patience=patience, verbose=True, path=path_model)\n",
    "\n",
    "    pbar_epoch = tqdm(total=num_epochs, position=1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        dic_records[\"train\"][\"lst_loss_batch\"] = []\n",
    "        dic_records[\"val\"][\"lst_loss_batch\"] = []\n",
    "        train_outputs = np.empty(shape=(len(train)))\n",
    "        val_outputs = np.empty(shape=(len(val)))\n",
    "\n",
    "        pbar_batch = tqdm(total=len(train_loader), position=2)\n",
    "\n",
    "        for i, train_batch in enumerate(train_loader):\n",
    "\n",
    "            # Allow training <=> moving weights\n",
    "            model.train()\n",
    "\n",
    "            # Remember index on train data\n",
    "            start_ind = i * batch_size\n",
    "            end_ind = start_ind + batch_size\n",
    "\n",
    "            # Send to GPU\n",
    "            X = train_batch[\"features\"].to(DEVICE)\n",
    "            y = train_batch[\"label\"].to(DEVICE)\n",
    "            w = train_batch[\"weights\"].to(DEVICE)\n",
    "            r = train_batch[\"resps\"].to(DEVICE)\n",
    "            a = train_batch[\"actions\"].to(DEVICE)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(X.float())\n",
    "            loss = p1_utility_loss(a.to(DEVICE), outputs[:,0].to(DEVICE), w.to(DEVICE), r.to(DEVICE))\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save \n",
    "            dic_records[\"train\"][\"lst_loss_batch\"].append(loss.item())\n",
    "            train_outputs[start_ind:end_ind] = outputs[:,0].cpu().detach().numpy()\n",
    "            pbar_batch.update(1)\n",
    "\n",
    "        # compute loss on validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i_, val_batch in enumerate(val_loader):\n",
    "\n",
    "                # Remember index on validation data\n",
    "                start_ind_ = i_ * batch_size\n",
    "                end_ind_ = start_ind_ + batch_size\n",
    "\n",
    "                # Send to GPU\n",
    "                X_ = val_batch[\"features\"].to(DEVICE)\n",
    "                y_ = val_batch[\"label\"].to(DEVICE)\n",
    "                w_ = val_batch[\"weights\"].to(DEVICE)\n",
    "                r_ = val_batch[\"resps\"].to(DEVICE)\n",
    "                a_ = val_batch[\"actions\"].to(DEVICE)\n",
    "\n",
    "                # Compute\n",
    "                outputs_ = model(X_.float())\n",
    "                loss_ = p1_utility_loss(a_.to(DEVICE), outputs_[:,0].to(DEVICE), w_.to(DEVICE), r_.to(DEVICE))\n",
    "                # Save\n",
    "                dic_records[\"val\"][\"lst_loss_batch\"].append(loss_.item())\n",
    "                val_outputs[start_ind_:end_ind_] = outputs_[:,0].cpu().detach().numpy()\n",
    "        dic_records[\"train\"][\"lst_loss_epoch\"].append(np.mean(dic_records[\"train\"][\"lst_loss_batch\"]))\n",
    "        dic_records[\"val\"][\"lst_loss_epoch\"].append(np.mean(dic_records[\"val\"][\"lst_loss_batch\"]))\n",
    "\n",
    "        # Early Stopping on loss function\n",
    "        train_actions = (train_outputs > threshold).astype(int)\n",
    "        train_utility = utility(dates=train.date.values, weights=train.weight.values, true_resp=train.resp.values, actions=train_actions)\n",
    "        train_accuracy = accuracy_score((train.resp > 0).astype(int), train_actions)\n",
    "        train_precision = precision_score((train.resp > 0).astype(int), train_actions)\n",
    "        train_recall = recall_score((train.resp > 0).astype(int), train_actions)\n",
    "        dic_records[\"train\"][\"lst_utility\"].append(train_utility)\n",
    "        dic_records[\"train\"][\"lst_accuracy\"].append(train_accuracy)\n",
    "        dic_records[\"train\"][\"lst_precision\"].append(train_precision)\n",
    "        dic_records[\"train\"][\"lst_recall\"].append(train_recall)\n",
    "            \n",
    "        val_actions = (val_outputs > threshold).astype(int)\n",
    "        val_utility = utility(dates=val.date.values, weights=val.weight.values, true_resp=val.resp.values, actions=val_actions)\n",
    "        val_accuracy = accuracy_score((val.resp > 0).astype(int), val_actions)\n",
    "        val_precision = precision_score((val.resp > 0).astype(int), val_actions)\n",
    "        val_recall = recall_score((val.resp > 0).astype(int), val_actions)\n",
    "        dic_records[\"val\"][\"lst_utility\"].append(val_utility)\n",
    "        dic_records[\"val\"][\"lst_accuracy\"].append(val_accuracy)\n",
    "        dic_records[\"val\"][\"lst_precision\"].append(val_precision)\n",
    "        dic_records[\"val\"][\"lst_recall\"].append(val_recall)\n",
    "            \n",
    "        msg1 = '~~~ Epoch [{}/{}], Loss train: {:.4f}, Loss val {:.4f}'.format(\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    dic_records[\"train\"][\"lst_loss_epoch\"][-1],\n",
    "                    dic_records[\"val\"][\"lst_loss_epoch\"][-1]\n",
    "        )\n",
    "        msg2 = '~~~ train utility: {:.4f}, val utility {:.4f}'.format(\n",
    "                    dic_records[\"train\"][\"lst_utility\"][-1],\n",
    "                    dic_records[\"val\"][\"lst_utility\"][-1]\n",
    "        )\n",
    "        pbar_epoch.update(1)\n",
    "        pbar_epoch.write(msg1)\n",
    "        pbar_epoch.write(msg2)\n",
    "\n",
    "        early_stopping(dic_records[\"val\"][\"lst_loss_epoch\"][-1], model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011637,
     "end_time": "2021-02-24T17:41:56.836161",
     "exception": false,
     "start_time": "2021-02-24T17:41:56.824524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Save dict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T17:41:56.863459Z",
     "iopub.status.busy": "2021-02-24T17:41:56.862812Z",
     "iopub.status.idle": "2021-02-24T17:41:56.865783Z",
     "shell.execute_reply": "2021-02-24T17:41:56.865357Z"
    },
    "papermill": {
     "duration": 0.017969,
     "end_time": "2021-02-24T17:41:56.865881",
     "exception": false,
     "start_time": "2021-02-24T17:41:56.847912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SAVE_DICT:\n",
    "    with open(\"./dic_records_training_StackedModel.json\", \"w\") as out:  \n",
    "        json.dump(dic_records, out) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011923,
     "end_time": "2021-02-24T17:41:56.890113",
     "exception": false,
     "start_time": "2021-02-24T17:41:56.878190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Load StackedModel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T17:41:56.920581Z",
     "iopub.status.busy": "2021-02-24T17:41:56.919814Z",
     "iopub.status.idle": "2021-02-24T17:42:01.519882Z",
     "shell.execute_reply": "2021-02-24T17:42:01.518863Z"
    },
    "papermill": {
     "duration": 4.61768,
     "end_time": "2021-02-24T17:42:01.520021",
     "exception": false,
     "start_time": "2021-02-24T17:41:56.902341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedModel(\n",
       "  (model0): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=18, out_features=36, bias=True)\n",
       "    (dense1): Linear(in_features=36, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model1): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=18, out_features=36, bias=True)\n",
       "    (dense1): Linear(in_features=36, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model2): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=18, out_features=36, bias=True)\n",
       "    (dense1): Linear(in_features=36, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model3): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=18, out_features=36, bias=True)\n",
       "    (dense1): Linear(in_features=36, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model4): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=18, out_features=36, bias=True)\n",
       "    (dense1): Linear(in_features=36, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model5): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=9, out_features=18, bias=True)\n",
       "    (dense1): Linear(in_features=18, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model6): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=41, out_features=82, bias=True)\n",
       "    (dense1): Linear(in_features=82, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model7): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=3, out_features=6, bias=True)\n",
       "    (dense1): Linear(in_features=6, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model8): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=3, out_features=6, bias=True)\n",
       "    (dense1): Linear(in_features=6, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model9): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=22, out_features=44, bias=True)\n",
       "    (dense1): Linear(in_features=44, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model10): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=3, out_features=6, bias=True)\n",
       "    (dense1): Linear(in_features=6, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model11): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=11, out_features=22, bias=True)\n",
       "    (dense1): Linear(in_features=22, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model12): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=17, out_features=34, bias=True)\n",
       "    (dense1): Linear(in_features=34, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model13): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=17, out_features=34, bias=True)\n",
       "    (dense1): Linear(in_features=34, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model14): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=4, out_features=8, bias=True)\n",
       "    (dense1): Linear(in_features=8, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model15): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=27, out_features=54, bias=True)\n",
       "    (dense1): Linear(in_features=54, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model16): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (dense1): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model17): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=28, out_features=56, bias=True)\n",
       "    (dense1): Linear(in_features=56, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model18): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=3, out_features=6, bias=True)\n",
       "    (dense1): Linear(in_features=6, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model19): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (dense1): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model20): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=6, out_features=12, bias=True)\n",
       "    (dense1): Linear(in_features=12, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model21): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=6, out_features=12, bias=True)\n",
       "    (dense1): Linear(in_features=12, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model22): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=10, out_features=20, bias=True)\n",
       "    (dense1): Linear(in_features=20, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model23): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(98, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=49, out_features=98, bias=True)\n",
       "    (dense1): Linear(in_features=98, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model24): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=13, out_features=26, bias=True)\n",
       "    (dense1): Linear(in_features=26, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model25): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=13, out_features=26, bias=True)\n",
       "    (dense1): Linear(in_features=26, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model26): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=13, out_features=26, bias=True)\n",
       "    (dense1): Linear(in_features=26, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model27): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=13, out_features=26, bias=True)\n",
       "    (dense1): Linear(in_features=26, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (model28): TagModel(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batch_norm0): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm1): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense0): Linear(in_features=13, out_features=26, bias=True)\n",
       "    (dense1): Linear(in_features=26, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (batch_norm0): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_norm1): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dense0): Linear(in_features=30, out_features=60, bias=True)\n",
       "  (dense1): Linear(in_features=60, out_features=5, bias=True)\n",
       "  (dense2): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "torch.cuda.empty_cache()\n",
    "model = StackedModel(\n",
    "        dic_tags=dic_tags, path_weights=PATH_WEIGHT_TAGMODEL, date_training_tag=DATE_TRAINING_TAGMODEL,train_previous_layers=TRAIN_PREVIOUS_LAYERS, device=DEVICE\n",
    "    ).to(DEVICE)\n",
    "model.load_state_dict(torch.load(PATH_WEIGHT_STACKMODEL))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012803,
     "end_time": "2021-02-24T17:42:01.545881",
     "exception": false,
     "start_time": "2021-02-24T17:42:01.533078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T17:42:01.578802Z",
     "iopub.status.busy": "2021-02-24T17:42:01.578253Z",
     "iopub.status.idle": "2021-02-24T17:46:50.870163Z",
     "shell.execute_reply": "2021-02-24T17:46:50.869713Z"
    },
    "papermill": {
     "duration": 289.31159,
     "end_time": "2021-02-24T17:46:50.870294",
     "exception": false,
     "start_time": "2021-02-24T17:42:01.558704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55268c842cb487f8d42cf496910a0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import janestreet\n",
    "env = janestreet.make_env()\n",
    "env_iter = env.iter_test()\n",
    "\n",
    "for (test_df, pred_df) in tqdm(env_iter):\n",
    "    \n",
    "    if test_df['weight'].values[0] > 0:\n",
    "        x_tt = test_df.loc[:, LST_FEATURES].values\n",
    "        \n",
    "        if np.isnan(x_tt.sum()):\n",
    "            x_tt = np.nan_to_num(x_tt) + np.isnan(x_tt) * f_mean.values.reshape(1, -1)\n",
    "        \n",
    "        pred = model(torch.tensor(x_tt, dtype=torch.float).to(DEVICE)).detach().cpu().numpy()\n",
    "        int_pred = int(pred >= THRESHOLD)\n",
    "        \n",
    "        pred_df[\"action\"].values[0] = int_pred\n",
    "    \n",
    "    else:\n",
    "        pred_df[\"action\"].values[0] = 0\n",
    "    \n",
    "    env.predict(pred_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 371.718214,
   "end_time": "2021-02-24T17:46:52.982456",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-24T17:40:41.264242",
   "version": "2.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1a6b49c7aeac4e1c898c83ba5b72cbcc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4658de42ac8148c4a63febb67f0896d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "47254642679e42a4be242d5157c6a73a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4917ed05e6ef441ca6d67c99e83b1f8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9ed94af6559a431b989fb184785f866d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f85c50cab154edba5dd9f726a689c6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9ed94af6559a431b989fb184785f866d",
       "placeholder": "​",
       "style": "IPY_MODEL_9fbbbd79795a449785ee3a8bfcdc48ba",
       "value": "15219it [04:49, 106.52it/s]"
      }
     },
     "9fbbbd79795a449785ee3a8bfcdc48ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ba21a7d5014248c6bc6797fbdb537308": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1a6b49c7aeac4e1c898c83ba5b72cbcc",
       "placeholder": "​",
       "style": "IPY_MODEL_4917ed05e6ef441ca6d67c99e83b1f8f",
       "value": ""
      }
     },
     "c55268c842cb487f8d42cf496910a0e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ba21a7d5014248c6bc6797fbdb537308",
        "IPY_MODEL_fa7d9738c0784141a24786f78295719a",
        "IPY_MODEL_9f85c50cab154edba5dd9f726a689c6c"
       ],
       "layout": "IPY_MODEL_47254642679e42a4be242d5157c6a73a"
      }
     },
     "fa7d9738c0784141a24786f78295719a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fcbadf7b8ae845b287886d889eae4c0e",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4658de42ac8148c4a63febb67f0896d8",
       "value": 1.0
      }
     },
     "fcbadf7b8ae845b287886d889eae4c0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
